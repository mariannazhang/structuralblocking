---
title: Data analysis plan for "Essentially blocked: 
Can structural factors block the essentialist effects of formal explanations?"
author: "Marianna Zhang (marianna.zhang@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
  pdf_document:
    toc: yes
    toc_depth: '3'
---

## Introduction

<!-- Abstract.-->


<!-- A description of the stimuli and procedures in this experiment.-->






This project's [repository](https://github.com/mariannazhang/structuralblocking) and [preregistration]( ) can be found online. 


## Methods

### Power Analysis



### Planned Sample

<!-- Planned sample size and/or termination rule, sampling frame, known demographics if any, preselection rules if any.-->

Planned sample size is ____ 5-year-olds and ____ 6-year-olds recruited from a university preschool and museums, as well as ____ adults recruited on Amazon Mechanical Turk. MTurk participants will be required to be located within the United States, and will be required to have a HIT acceptance rate of 80% or above.

### Materials



### Procedure	



The adult survey paradigm can be found [on Qualtrics](_____). 

### Analysis Plan

<!-- data cleaning rules, data exclusion rules, covariates, etc. Key analysis of interest. Can also pre-specify additional analyses you plan to do.-->

#### Exclusion criteria


#### Analysis of interest






### Methods Addendum (Post Data Collection)
#### Actual Sample
<!-- actual sample size, actual power, exclusions, demographics --> 



#### Differences from pre-data collection methods plan





## Results


### Data preparation

Data preparation as specified in the analysis plan.

```{r "knitr config", cache = FALSE}
require("knitr")
```


```{r}
#### Load relevant libraries and functions
library(tidyverse)


#### Import data for analysis
data_pilot_children <- read_csv("../data/FYP_data_pilot_children.csv")


#### Data exclusion / filtering
# Replace NAs in debriefing questions with text " " to prep for str_detect, which can't handle NAs
data$debrief_1 <- str_replace_na(data$debrief_1, " ")

# Record exclusions
data_excl <- tibble(
  attn = sum(data$attn != "Yes" | is.na(data$attn)), 
  IH_C = sum(data$IH_C1 != 3 | is.na(data$IH_C1) | data$IH_C2 != 7 | is.na(data$IH_C2)),
  non_naive = sum(str_detect(data$debrief_1, "is-ought"))
  + sum(str_detect(data$debrief_2, "is-ought"))
  + sum(str_detect(data$debrief_3, "is-ought"))
  + sum(str_detect(data$debrief_4, "is-ought")))
data_excl

# Exclude subjects who didn't pass check questions
data <- data %>%
  filter(check_game == "Yes" & 
         check_bucket_boy_1 == "One of the buckets is bigger") %>%
  select(-starts_with("check")) # Delete check columns


#### Demographics analysis
# Gender
data_demographics_gender <- data %>%
  count(gender)
data_demographics_gender

# Age
data_demographics_age <- data %>%
  count(age)
data_demographics_age


#### Prepare data for analysis
# Gather to tidy long form
data_tidy <- data %>% 
  gather(question, response, starts_with("es"))

# Recode essentialism variables
data_tidy$es_stability_past <- data_tidy$es_stability_past %>% 
  recode("No" = 0,
         "Yes" = 1)
data_tidy$es_stability_future <- data_tidy$es_stability_future %>% 
  recode("No" = 0,
         "Yes" = 1)
data_tidy$es_innateness_stop <- data_tidy$es_innateness_stop %>% 
  recode("No" = 1,
         "Yes" = 0)
data_tidy$es_innateness_switch <- data_tidy$es_innateness_switch %>% 
  recode("For sure Green-Ball" = ,
         "Maybe Green-Ball" = ,
         "Maybe Yellow-Ball" = ,
         "Maybe Yellow-Ball" = ,)
data_tidy$es_inductivePoten <- data_tidy$es_inductivePoten %>% 
  recode("Just this girl" = 0,
         "A few girls" = 0.5,
         "A whole lot of girls" = 1)

# Calculate essentialism measure per subject
data_means_subj <- data_tidy %>% 
  group_by(subject) %>% 
  mutate(essentialism = mean(starts_with("es"), na.rm = TRUE))
```

### Preliminary look at data and visualization
```{r}
# Summarize essentialism measure across subjects by condition
data_means <- data_tidy %>%
  group_by(context, explanation) %>% 
  summarize(essentialism = mean(starts_with("es"), na.rm=TRUE),
            sd = sd(response, na.rm=TRUE), 
            n())
data_means
```

```{r}
ggplot(data_means_subj, aes(x = context, y = essentialism, color = explanation)) +
  geom_point(position = position_jitter(height = 0, width = 0.1),
             alpha = 0.5) + 
  stat_summary(fun.data = "mean_cl_boot", # 95% confidence intervals
               geom = "linerange",
               size = 1) + 
  stat_summary(fun.y = "mean",
               geom = "point",
               shape = 21,
               color = "black",
               fill = "white",
               size = 4) +
  scale_fill_brewer(palette = "Set1") +
  scale_y_continuous(limits = c(0, 1))

```

### Target analysis

The analyses as specified in the analysis plan. 

```{r}
# fit the linear models
fit_compact = lm(essentialism ~ 1, data = data_means_subj)
fit_augmented = lm(essentialism ~ 1 + context * explanation, data = data_means_subj)

# run the F test
anova(fit_compact, fit_augmented)
```


### Exploratory analyses
```{r}

```




## Discussion



